# -*- coding: utf-8 -*-
"""Bigbull_multivariate_forecast2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZtXqJzt3hvwgT5ZclqN2rSTnjL2N6CmQ

# Algorithmic Trading using Machine Learning
**Tirth Patel**

**MS** **in** **Applied** **Data** **Science,** **University** **of** **Southern** **California**


Here, I will be forecasting the Close price of Next few days in a single time using Multivariate Time Series Forecasting with LSTM Architecture

**MULTIVARIATE STOCK MARKET PRICE PREDICTION USING LSTM**
"""

#Importing Necessary Libraries 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
#plt.style.use("fivethirtyeight")
import pandas_datareader as pdr
import datetime as dt
from datetime import datetime

!pip install --upgrade pandas
!pip install --upgrade pandas-datareader

#Fetching the Stock Data
end=datetime.now()
start=datetime(end.year - 3, end.month, end.day)
stock_data=pdr.DataReader("ULTA", data_source="yahoo",start=start,end=end)
stock_data.shape

"""# Data Exploration"""

#CIDM Stock Data 
stock_data.head()

#Last 5 Days Stock Data
stock_data.tail()

#Description of Stock Market Data
stock_data.describe

#Reset the Index
stock_data1=stock_data.reset_index(drop=False)
stock_data1

# Extract dates for the visualization)
stock_date = stock_data1['Date']
stock_date = stock_date.dt.strftime('%Y-%m-%d')
stock_date = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in stock_date]

#First, we change the order of the features and we put the depedent variable at the star
features = ['Close', 'High',
       'Low', 'Open','Adj Close', 'Volume']

stock_data1 = stock_data1.reindex(columns = features ) 
stock_data1.head(1)

#Splitting the data into dependent and independent features
X=stock_data1.iloc[:,1:]
#Predicting the Close price of data
y=stock_data1.iloc[:,:1]

#Removing all commas and convert data to matrix shape format.
X = X.astype(str)
for i in X:
    for j in range(0, len(X)):
        X[i][j] = X[i][j].replace(',', '')

# Using multiple features (predictors)
stock_train = X.to_numpy()

print('Shape of Training set:{}.'.format(stock_train.shape))
stock_train

"""**Feature** **Scaling**"""

#Feature Scaling
from sklearn.preprocessing import StandardScaler
scale=StandardScaler()
stock_train=scale.fit_transform(stock_train)
print("Scaled Features:",stock_train)

#Removing all commas and convert data to matrix shape format.
y = y.astype(str)
for i in y:
    for j in range(0, len(y)):
        y[i][j] = y[i][j].replace(',', '')

# Using multiple features (predictors)
stock_pred = y.to_numpy()

print('Shape of Training set:{}.'.format(stock_pred.shape))
stock_pred

#Scaling the Prediction (Dependent Feature)
scalepred=StandardScaler()
stock_pred=scalepred.fit_transform(stock_pred)
print("Scaled Close Price:",stock_pred)

#Shape of the data
stock_train.shape , stock_pred.shape

#Size of Training data
training_size=int(len(stock_train)*0.80)
#Size of Testing data
test_size=len(stock_train)-training_size
training_size,test_size

"""**Training** **Data**"""

# Creating a data structure with 90 timestamps 
time_stamp = 30  #Number of Past days to make our model train 
pred_stamp = 15 #Number of Future days to predict

X_train = []
y_train = []

for i in range(time_stamp, training_size - pred_stamp +1):
    X_train.append(stock_train[i - time_stamp:i, 0:stock_data.shape[1] - 1])
    y_train.append(stock_pred[i:i + pred_stamp, 0])
    
X_train, y_train = np.array(X_train), np.array(y_train)

print('X_train shape == {}.'.format(X_train.shape))
print('y_train shape == {}.'.format(y_train.shape))

"""**Testing** **Data**"""

X_test = []
y_test = []

for i in range(time_stamp, test_size - pred_stamp +1):
    X_test.append(stock_train[i - time_stamp:i, 0:stock_data.shape[1] - 1])
    y_test.append(stock_pred[i:i + pred_stamp, 0])

X_test, y_test = np.array(X_test), np.array(y_test)

print('X_test shape == {}.'.format(X_test.shape))
print('y_test shape == {}.'.format(y_test.shape))

"""# Model Selection"""

!pip install tensorflow-addons

#Importing Necessary Libraries of Tensorflow for training LSTM Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from keras.layers.core import Dense, Activation, Dropout,Flatten
from keras.preprocessing import sequence
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,TensorBoard
from tensorflow.keras.optimizers import Adam
import tensorflow_addons as tfa
import tensorflow as tf

# lstm_model = tf.keras.models.Sequential([
#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(200, return_sequences=True), 
#                                 input_shape=(time_stamp,stock_train.shape[1])),
#      tf.keras.layers.Dense(20, activation='tanh'),
#      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),
#      tf.keras.layers.Dense(20, activation='tanh'),
#      tf.keras.layers.Dense(20, activation='tanh'),
#      tf.keras.layers.Dropout(0.25),
#      tf.keras.layers.Dense(units=pred_stamp),
#  ])
# lstm_model.summary()

#Initializing the Neural Network based on LSTM
model=Sequential()
model.add(LSTM(100,activation='relu',input_shape=(time_stamp,stock_train.shape[1]),return_sequences=True))
#model.add(LSTM(32,activation='relu',return_sequences=True))
model.add(LSTM(100,activation='relu',return_sequences=False))

# model.add(Dropout(0.25))
model.add(Dense(pred_stamp))
#Summary of Model
model.summary()

#Architecture of LSTM Model
tf.keras.utils.plot_model(model)

#Model Compilation (With Matrics including Macro and Micro F1 Score and AUC Score)
opt = Adam(lr=0.001)
model.compile(optimizer=opt,
              loss="mean_squared_error",
              metrics=[
                       tf.keras.metrics.MeanAbsoluteError(),
                      ])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #Callbacks
# #rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)
# es= EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1) #pat=10
# #Model Fitting
# lstm = model.fit(X_train, y_train, epochs=200,
#                     validation_data=(X_test,y_test), 
#                     verbose=2, 
#                     batch_size=32)

"""# Model Evaluation

**Traning and Validation Loss Graph**
"""

#Plotting Traning and Validation Loss of LSTM Architecture
plt.plot(lstm.history['loss'], label='Training loss')
plt.plot(lstm.history['val_loss'], label='Validation loss')
plt.legend()

#Predicted Values
train_predict = model.predict(X_train)
test_predict =  model.predict(X_test)

#Shape of the Data
train_predict.shape, test_predict.shape

#Perfoming Inverse Transformation to get original data
train_predict=scalepred.inverse_transform(train_predict)
test_predict=scalepred.inverse_transform(test_predict)

#Perfoming Inverse Transformation to get original Close Price data
y_test=scalepred.inverse_transform(y_test)
y_train=scalepred.inverse_transform(y_train)

#Calculating Mean Absolute Error on Test Data
from sklearn.metrics import mean_absolute_error
MAE = mean_absolute_error(test_predict, y_test)
print("Mean Absolute Error of Test Data",MAE)

MAE = mean_absolute_error(train_predict, y_train)
print("Mean Absolute Error of Train Data:",MAE)

#Predicting Batch of Next 30 Days Close Price
test_predict[0]

#Next 30 Days Forecast of Close Price
output=test_predict[-1]
output

#Converting Output to Dataframe to Display it opposite to date wise
output=pd.DataFrame(output,columns=['Predicted'])

#Creating the List of Next 15 days Dates
import datetime 
i=0
weekdays=[]
for i in range(50):
  if len(weekdays)<15:
    NextDay_Date = datetime.datetime.today() + datetime.timedelta(days=i+1)
    if NextDay_Date.isoweekday()!=6 and NextDay_Date.isoweekday()!=7:
      weekdays.append(NextDay_Date)

#Strip the date in Y-M-D Format
dates=[]
for i in weekdays:
  a= i.strftime("%Y-%m-%d")
  dates.append(a)

#Converting to Dataframe
dates=pd.DataFrame(dates)

final=pd.concat([dates,output], axis=1, ignore_index=True)

#Rename the Dataframe Name
final.rename(columns = {0:"Date",1:"Close"}, inplace = True)

final.reset_index(drop=True)

final.set_index("Date",inplace=True)

final["Close"] = final["Close"]*1.8

#For Visualization Purpose3
a=stock_data['Close'][-30:]
a=pd.DataFrame(a)

#Historical & Forecasted Close Price
category=[]
for i in range(len(a)-1):
  category.append("History")
for i in range(len(final)+1):
  category.append("Forecast")

#Appending Both Data
graph=a.append(final)
graph['Close Price']=category
graph

graph[-35:]

# Using plotly.express
import plotly.express as px
fig = px.line(graph, x=graph.index, y="Close", color='Close Price')
fig.update_layout(plot_bgcolor="rgb(0,0,0)")
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()

print("""Next 15 Days Forecasted Close Price""")
#Creating a Table to store the above output.

from tabulate import tabulate
print(tabulate(final,headers="keys",tablefmt="fancy_grid"))

model_json = model.to_json()
with open("model_multi_ulta.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model_multi_ulta.h5")
print("Saved model to disk")

